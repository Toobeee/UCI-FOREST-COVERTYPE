# -*- coding: utf-8 -*-
"""Optimization_UCI_03.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JVekoTIQuN2fwtNHDSMgbGRXqXHweoch

## ðŸ“Œ Step 1: Load and Preprocess the Data
"""

from sklearn.datasets import fetch_covtype
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.utils import to_categorical

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Load data
data = fetch_covtype()
X, y = data.data, data.target - 1  # make 0-indexed

X.shape

# Class distribution
plt.figure(figsize=(8,4))
sns.countplot(x=y)
plt.title("Cover Type Distribution")
plt.xlabel("Cover Type")
plt.ylabel("Count")
plt.grid(axis='y')
plt.show()

print("\nClass distribution:")
print(pd.Series(y).value_counts().sort_index())

# Train/Test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

X_train.shape

# Standardize inputs
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# # One-hot encode labels
# y_train_cat = to_categorical(y_train, num_classes=7)
# y_test_cat = to_categorical(y_test, num_classes=7)

"""## ðŸ“Œ Step 2: Define and Train a Baseline MLP Model"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.optimizers import SGD, Adam

baseline_model = Sequential([
    Input(shape=(X_train.shape[1],)),
    Dense(132, activation='relu'),
    Dense(68, activation='relu'),
    Dense(36, activation='relu'),
    Dense(7, activation='softmax')
])

baseline_model.summary()

baseline_model.compile(optimizer=Adam(learning_rate=0.01),
                       loss='sparse_categorical_crossentropy',
                       metrics=['accuracy'])

"""## TRAINING OF MODEL"""

history_baseline = baseline_model.fit(X_train, y_train,
                                      validation_split=0.2,
                                      epochs=15,
                                      batch_size=100,
                                      verbose=1)

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

def plot_learning_curves(history, title='Model'):
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    epochs = range(1, len(acc) + 1)

    plt.figure(figsize=(12, 5))

    # Accuracy plot
    plt.subplot(1, 2, 1)
    plt.plot(epochs, acc, 'b-', label='Train Accuracy')
    plt.plot(epochs, val_acc, 'r--', label='Val Accuracy')
    plt.title(f'{title} - Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)

    # Loss plot
    plt.subplot(1, 2, 2)
    plt.plot(epochs, loss, 'b-', label='Train Loss')
    plt.plot(epochs, val_loss, 'r--', label='Val Loss')
    plt.title(f'{title} - Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

plot_learning_curves(history_baseline, title='Baseline Model')

"""### Evaluate model's performance"""

loss1, acc1 = baseline_model.evaluate(X_test, y_test)
print(f"Test accuracy : {100*acc1:.2f}%")
print(f"Test loss     : {100*loss1:.2f}%")

"""## MODEL IS OVERFITTING
-- REGULARIZATION
-- EARLY STOPPING

## -- DROPOUT
"""

from tensorflow.keras import models, layers

def build_dropout_model():
    model = models.Sequential([
        layers.Input(shape=(54,)),
        layers.Dense(512, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(512, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(10, activation='softmax')
    ])
    return model

reg_model_1 = build_dropout_model()
reg_model_1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

reg_model_1.summary()

print(X_train.shape)
print(y_train.shape)

history_reg_1 = reg_model_1.fit(X_train, y_train, epochs=20, validation_split=0.2, batch_size=128)





"""## earlystopping"""

history_reg_1 = reg_model_1.fit(X_train, y_train, epochs=20, validation_split=0.2, batch_size=128)

from keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

reg_model_1.fit(X_train, y_train, epochs=50, validation_split=0.2, batch_size=128, callbacks=[early_stop])

from keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

reg_model_1.fit(X_train, y_train, epochs=100, validation_split=0.2, batch_size=128, callbacks=[early_stop])

plot_learning_curves(history_reg_1, title='Dropout Regularized Model')

"""## L2 Regularization"""

from tensorflow.keras import regularizers

def build_l2_regularized_model():
    model = models.Sequential([
        layers.Input(shape=(54,)),
        layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
        layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
        layers.Dense(10, activation='softmax')
    ])
    return model

reg_model_2 = build_l2_regularized_model()
reg_model_2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

reg_model_2.summary()

history_reg_2 = reg_model_2.fit(X_train, y_train, epochs=30, validation_split=0.2, batch_size=128)

def build_regularized_model():
    model = models.Sequential([
        layers.Input(shape=(54,)),
        layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
        layers.Dropout(0.2),
        layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),
        layers.Dropout(0.2),
        layers.Dense(10, activation='softmax')
    ])
    return model

reg_model_3 = build_regularized_model()
reg_model_3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

reg_model_3.summary()

history_reg_3 = reg_model_3.fit(X_train, y_train, epochs=10, validation_split=0.2, batch_size=128)

plot_learning_curves(history_reg_3, title='Regularized Model')

# Evaluate on test set
models_dict = {
    "Baseline": baseline_model,
    "Dropout Regularized": reg_model_1,
    "L2 Regularized": reg_model_2,
    "Combined Regularized": reg_model_3
}

for name, model in models_dict.items():
    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
    print(f'{name} Model Test Accuracy: {test_acc:.4f}')

"""# Dropout Regularized Model Test Accuracy: 0.9330
-- trying to achieve 94%
"""

from tensorflow.keras.optimizers import Adam

reg_model_1.compile(
    optimizer=Adam(learning_rate=0.0005),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

from tensorflow.keras import regularizers

layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001))

from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

lr_scheduler = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=2,
    verbose=1,
    min_lr=1e-6
)

history = reg_model_1.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=100,
    batch_size=128,
    callbacks=[early_stop, lr_scheduler]
)

"""# 94% accuracy achieved

Evaluate Accuracy + Learning Curves
"""

# Evaluate on test data
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {test_accuracy:.4f}")

""". Precision, Recall, F1-Score"""

from sklearn.metrics import classification_report
import numpy as np

# Predict class labels
y_pred_probs = model.predict(X_test)
y_pred = np.argmax(y_pred_probs, axis=1)

# Generate classification report
print("Classification Report:")
print(classification_report(y_test, y_pred, digits=4))

"""
Confusion Matrix"""

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

"""Visualize Training & Validation Learning Curves"""

# Assuming you stored model history from training
# history = model.fit(...)

def plot_learning_curves(history):
    import matplotlib.pyplot as plt

    # Accuracy
    plt.figure(figsize=(14, 5))

    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Acc')
    plt.plot(history.history['val_accuracy'], label='Val Acc')
    plt.title('Accuracy over Epochs')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    # Loss
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.title('Loss over Epochs')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.tight_layout()
    plt.show()

# Call this after model.fit
plot_learning_curves(history)

"""COMPARISON WITH ENSEMBLE METHODS"""

from sklearn.ensemble import RandomForestClassifier
# Or use XGBoost
# from xgboost import XGBClassifier

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Random Forest
clf = RandomForestClassifier(n_estimators=100, random_state=42)
# For XGBoost, uncomment the line below
# clf = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)

clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

# Accuracy
acc = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {acc:.4f}")

# Precision, Recall, F1
print("\nClassification Report:")
print(classification_report(y_test, y_pred, digits=4))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix - Random Forest")
plt.show()



"""Tree-based ensemble models like Random Forests and XGBoost often outperform MLPs on structured/tabular data because they naturally capture nonlinear feature interactions, handle missing values, and are robust to outliers. Unlike MLPs, they donâ€™t require feature scaling and are better at interpreting categorical or ordinal relationships. Based on our results, the tree-based model may reach similar or even higher accuracy with much less hyperparameter tuning compared to neural networks."""